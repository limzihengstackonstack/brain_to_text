# real_loader.py
import os, zipfile, pickle, numpy as np
from scipy.io import loadmat

def _pick_best_key_from_mat(mat):
    cand = []
    for k, v in mat.items():
        if k.startswith("__"):
            continue
        try:
            arr = np.asarray(v)
            if arr.ndim >= 2 and arr.size > 0:
                cand.append((arr.size, k))
        except Exception:
            pass
    if not cand:
        raise ValueError("åœ¨ .mat å…§æ‰¾ä¸åˆ°åˆé©çš„æ•¸æ“š key")
    cand.sort(reverse=True)
    return cand[0][1]

def load_signals_from_zip(zip_path):
    """å›žå‚³ X_tc: (T, C) float32"""
    if not os.path.exists(zip_path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° zip æª”ï¼š{zip_path}")

    with zipfile.ZipFile(zip_path, "r") as z:
        names = [i.filename for i in z.infolist() if not i.is_dir()]
        print("ðŸ“¦ ZIP å…§æª”æ¡ˆï¼ˆå‰ 10 å€‹ï¼‰:", names[:10])

        # å…ˆå„ªå…ˆæŒ‘ hdf5 çš„ train æª”ï¼Œå†é€€è€Œæ±‚å…¶æ¬¡
        pick = None
        for nm in names:
            if nm.lower().endswith(".hdf5") and "data_train" in nm.lower():
                pick = nm;
                break
        if pick is None:
            for ext in [".hdf5", ".mat", ".npy", ".npz", ".csv", ".txt"]:
                for nm in names:
                    if nm.lower().endswith(ext):
                        pick = nm;
                        break
                if pick: break
        if pick is None:
            raise ValueError("ZIP å…§æ²’æœ‰æ”¯æ´çš„å‰¯æª”å")

        out_dir = os.path.dirname(zip_path)
        # ðŸ‘‰ ä¿ç•™ ZIP å…§çš„å­è³‡æ–™å¤¾å±¤ç´šï¼Œé¿å…è·¯å¾‘éŒ¯èª¤
        out_path = os.path.normpath(os.path.join(out_dir, pick))
        if not os.path.exists(out_path):
            z.extract(pick, out_dir)

    ext = os.path.splitext(out_path)[1].lower()
    print(f"âœ… é¸ç”¨æª”æ¡ˆï¼š{pick}ï¼ˆ{ext}ï¼‰ â†’ {out_path}")

    # === æ ¹æ“šå‰¯æª”åè®€å–è³‡æ–™ ===
    if ext in ['.zip']:
        # TODO: é€™è£¡è™•ç† ZIP çš„é‚è¼¯ï¼ˆå¦‚æžœæœ‰çš„è©±ï¼‰
        pass

    elif ext in ['.hdf5', '.h5']:
        import h5py

        def pick_largest_2d_from_group(g):
            best_name, best_size, best_shape = None, -1, None
            stack = [g]
            while stack:
                gg = stack.pop()
                for name, obj in gg.items():
                    if isinstance(obj, h5py.Group):
                        stack.append(obj)
                    elif isinstance(obj, h5py.Dataset) and obj.ndim >= 2:
                        size = int(np.prod(obj.shape))
                        if size > best_size:
                            best_name, best_size, best_shape = obj.name, size, obj.shape
            return best_name, best_shape  # å¯èƒ½ç‚º (None, None)

        with h5py.File(out_path, "r") as f:
            top_keys = list(f.keys())
            print("ðŸ“‚ HDF5 å…§éƒ¨ keys:", top_keys[:20])

            arrays = []
            chosen = []
            for tk in top_keys:
                obj = f[tk]
                if isinstance(obj, h5py.Dataset) and obj.ndim >= 2:
                    arr = np.array(obj).astype(np.float32)
                    src_name = obj.name
                elif isinstance(obj, h5py.Group):
                    name, shp = pick_largest_2d_from_group(obj)
                    if name is None:
                        print(f"  âš ï¸ {tk}: æ‰¾ä¸åˆ° 2D datasetï¼Œè·³éŽ")
                        continue
                    arr = np.array(f[name]).astype(np.float32)
                    src_name = name
                else:
                    print(f"  âš ï¸ {tk}: ä¸æ˜¯ group æˆ– 2D datasetï¼Œè·³éŽ")
                    continue

                arr = np.squeeze(arr)
                if arr.ndim != 2:
                    print(f"  âš ï¸ {tk}: shape={arr.shape} ä¸æ˜¯ 2Dï¼Œè·³éŽ")
                    continue

                # æœŸæœ› (T, C)ï¼Œè‹¥åƒ (C, T) å°±è½‰ç½®ï¼ˆé€šå¸¸ T >> Cï¼‰
                if arr.shape[0] <= arr.shape[1]:
                    arr = arr.T

                arrays.append(arr)
                chosen.append((tk, src_name, arr.shape))
                print(f"  âœ… {tk}: ä½¿ç”¨ {src_name} shape={arr.shape}")

                if not arrays:
                    raise ValueError("HDF5 å…§å±¤æ²’æ‰¾åˆ°å¯ç”¨ 2D è³‡æ–™é›†")

                # --- çµ±ä¸€é€šé“æ•¸ï¼ˆé€™è£¡è²¼æ–¹æ¡ˆ2ï¼‰---
                channels = [a.shape[1] for a in arrays]
                from collections import Counter
                target_C = Counter(channels).most_common(1)[0][0]

                kept = [a.astype(np.float32) for a in arrays if a.shape[1] == target_C]
                dropped = len(arrays) - len(kept)
                arrays = kept
                print(f"ðŸ”§ ä¿ç•™ C={target_C} çš„ trial={len(arrays)}ï¼Œä¸Ÿæ£„ {dropped} å€‹é€šé“æ•¸ä¸åŒçš„ trial")

                # --- ä¸²æŽ¥æ‰€æœ‰ trial ---
                X = np.concatenate(arrays, axis=0)
                print("ðŸ“ ä¸²æŽ¥å¾Œ X shape:", X.shape)

            return X  # (T, C)


def load_labels_pkl(pkl_path):
    """å¾ž pkl ä¸­å–å‡º per-timestep çš„éŸ³ç´  id åºåˆ— y_t: (T,) int64"""
    if not os.path.exists(pkl_path):
        raise FileNotFoundError(f"æ‰¾ä¸åˆ° pkl æª”ï¼š{pkl_path}")
    with open(pkl_path, "rb") as f:
        obj = pickle.load(f)

    if isinstance(obj, dict):
        # ä¾æ“šä½ å€‘ pkl çš„å¯¦éš› keys èª¿æ•´é€™è£¡çš„é¸å–®
        for key in ["phoneme_ids", "phonemes", "labels", "y"]:
            if key in obj:
                y_t = np.asarray(obj[key]).astype(np.int64).squeeze()
                print(f"âœ… ä½¿ç”¨ pkl keyï¼š{key}ï¼›y_t shape={y_t.shape}")
                return y_t
        raise KeyError(f"åœ¨ pkl è£¡æ‰¾ä¸åˆ°éŸ³ç´ åºåˆ—çš„ keyï¼Œå¯¦éš› keys={list(obj.keys())}")
    else:
        # pkl ä¸æ˜¯ dict çš„æƒ…æ³ï¼šå˜—è©¦è½‰æˆä¸€ç¶­
        y_t = np.asarray(obj).astype(np.int64).squeeze()
        if y_t.ndim != 1:
            raise ValueError(f"pkl å…§å®¹ä¸æ˜¯ 1 ç¶­ï¼Œshape={y_t.shape}")
        print(f"âœ… ç›´æŽ¥ä½¿ç”¨ pkl é™£åˆ—ï¼›y_t shape={y_t.shape}")
        return y_t

def make_windows(X_tc, y_t, win=200, stride=200):
    """æŠŠé•·åºåˆ—åˆ‡æˆè¦–çª—ï¼Œå›žå‚³ (N,T,C) èˆ‡ (N,T)"""
    T, C = X_tc.shape
    if len(y_t) < T:
        raise ValueError(f"æ¨™ç±¤é•·åº¦ {len(y_t)} < è³‡æ–™é•·åº¦ {T}ï¼Œè«‹ç¢ºèªå°é½Š")
    y_t = y_t[:T]
    xs, ys = [], []
    for s in range(0, T - win + 1, stride):
        e = s + win
        xs.append(X_tc[s:e]); ys.append(y_t[s:e])
    X = np.stack(xs).astype(np.float32)
    y = np.stack(ys).astype(np.int64)
    print("ðŸ“¦ åˆ‡çª—å¾Œ shapes:", X.shape, y.shape)
    return X, y
